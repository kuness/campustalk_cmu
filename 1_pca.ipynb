{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"1_pca.ipynb","provenance":[],"collapsed_sections":["3KOivr5YJ7EX","3JF2NSTKKCRV","y3biPt0YKDyy","lTiFFbVre_L1","GVwY2RCwKNI9","L0mvNN2Ce_MR","FegTOeSxe_Mf","-E8WXf0je_Ms","azB0OUfde_My","CsKuwmaSe_M8"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"RLpl3MXDJymq","colab_type":"text"},"source":["## You may ignore this. This is just for loading the files online. \n","\n","## (But you still have to run this [shift+enter])\n"]},{"cell_type":"code","metadata":{"id":"Bp0dBgMmfBmi","colab_type":"code","colab":{}},"source":["!wget -O iris_data.csv https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3KOivr5YJ7EX","colab_type":"text"},"source":["## Import important packages."]},{"cell_type":"code","metadata":{"id":"6MB0VDRle_Lh","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import math\n","from matplotlib import pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3JF2NSTKKCRV","colab_type":"text"},"source":["## Load the data"]},{"cell_type":"code","metadata":{"id":"xDFAYHRTe_Ln","colab_type":"code","colab":{}},"source":["iris = pd.read_csv('iris_data.csv', header = None)\n","iris.columns = ['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'class']\n","iris.dropna(how=\"all\", inplace=True) ## no need to drop but for other dataset, you may want this!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y3biPt0YKDyy","colab_type":"text"},"source":["## Take a quick glance at the data"]},{"cell_type":"code","metadata":{"id":"oX_fyDY2e_Lr","colab_type":"code","colab":{}},"source":["iris.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_EyH_5r6e_Lx","colab_type":"code","colab":{}},"source":["X = iris.iloc[:,0:4].values\n","y = iris.iloc[:,4].values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lTiFFbVre_L1","colab_type":"text"},"source":["## Expolatory Visualization"]},{"cell_type":"code","metadata":{"id":"uGzdXQpEe_L2","colab_type":"code","colab":{}},"source":["label_dict = {1: 'Setosa',\n","              2: 'Versicolor',\n","              3: 'Virgnica'}\n","\n","feature_dict = {0: 'sepal length',\n","                1: 'sepal width',\n","                2: 'petal length',\n","                3: 'petal width'}\n","\n","with plt.style.context('bmh'):\n","    plt.figure(figsize=(8, 6))\n","    for cnt in range(4):\n","        plt.subplot(2, 2, cnt+1)\n","        for lab in ('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'):\n","            plt.hist(X[y==lab, cnt],\n","                     label=lab,\n","                     bins=10,\n","                     alpha=0.4)\n","        plt.xlabel(feature_dict[cnt])\n","    plt.legend(loc='upper right', fancybox=True, fontsize=8)\n","\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GVwY2RCwKNI9","colab_type":"text"},"source":["## Standardize the data before finding covariance matrix."]},{"cell_type":"code","metadata":{"id":"7f1MxfC_e_L8","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import StandardScaler\n","X_std_sc = StandardScaler().fit_transform(X)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jquneLSTe_MA","colab_type":"text"},"source":["Covariance matrix formula:\n","\n","$$ \\Sigma = \\frac{1}{n-1} (\\mathbf{X} - \\bar{X})^T(\\mathbf{X} - \\bar{X})$$"]},{"cell_type":"code","metadata":{"id":"p9qJKj2Je_MB","colab_type":"code","colab":{}},"source":["X_mean = np.mean(X_std_sc, axis=0)\n","X_cov = (X_std_sc - X_mean).T.dot((X_std_sc - X_mean)) / (X_std_sc.shape[0]-1)\n","print('Covariance matrix \\n%s' %X_cov)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2H_2HPswe_MH","colab_type":"text"},"source":["We may use a built-in function from numpy to find covariance matrix, eigenvalues, and eigenvectors."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"O621tJ2ve_MJ","colab_type":"code","colab":{}},"source":["cov_mat = np.cov(X_std_sc.T)\n","\n","eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n","\n","print('Covariance matrix: \\n%s' %cov_mat)\n","print('Eigenvectors: \\n%s' %eig_vecs)\n","print('\\nEigenvalues: \\n%s' %eig_vals)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7RfxJ3M2e_MQ","colab_type":"text"},"source":["As in the slides, eigenvalues here are always greater than 0 because the covariance matrix is positive semi-definite. "]},{"cell_type":"markdown","metadata":{"id":"L0mvNN2Ce_MR","colab_type":"text"},"source":["## Selecting principal components\n"]},{"cell_type":"markdown","metadata":{"id":"RG1umTXHe_MS","colab_type":"text"},"source":["The eigen with the lowest value contains the least information. \n","\n","However, how do we know which one we can really drop?"]},{"cell_type":"code","metadata":{"id":"yedn1dk-e_MT","colab_type":"code","colab":{}},"source":["eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n","\n","eig_pairs.sort(key=lambda x: x[0], reverse=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tsS6rF4Xe_MY","colab_type":"code","colab":{}},"source":["total = sum(eig_vals)\n","var_exp = [(i / total)*100 for i in sorted(eig_vals, reverse=True)]\n","cum_var_exp = np.cumsum(var_exp)\n","\n","with plt.style.context('bmh'):\n","    plt.figure(figsize=(6, 4))\n","\n","    plt.bar(range(4), var_exp, alpha=0.5, align='center',\n","            label='explained variance')\n","    plt.step(range(4), cum_var_exp, where='mid',\n","             label='cumulative explained variance')\n","    plt.ylabel('Explained Variance Percentage')\n","    plt.xlabel('Eigenvectors')\n","    plt.legend(loc='best')\n","    plt.tight_layout()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LwT6tEBYe_Mc","colab_type":"code","colab":{}},"source":["var_exp"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FegTOeSxe_Mf","colab_type":"text"},"source":["## Forming a projection matrix"]},{"cell_type":"markdown","metadata":{"id":"z4rOAZKze_Mh","colab_type":"text"},"source":["Let's say we would like to drop 2 dimensions since the last 2 eigenvalues only contains 3.5 and 0.5% of the variance. The input should be a 4-dim vector and the output is a 2-dim vecotr. Hence, the projection matrix is supposed to be 4x2 matrix."]},{"cell_type":"code","metadata":{"id":"pcd3oG20e_Mi","colab_type":"code","colab":{}},"source":["eig_pairs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8r1t2BOe_Mm","colab_type":"code","colab":{}},"source":["proj_matrix = np.hstack((eig_pairs[0][1].reshape(4,1),\n","                      eig_pairs[1][1].reshape(4,1)))\n","\n","print('Projection Matrix :\\n', proj_matrix)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-E8WXf0je_Ms","colab_type":"text"},"source":["## Projection onto a new space"]},{"cell_type":"markdown","metadata":{"id":"-c1NF-gFe_Mt","colab_type":"text"},"source":["Now, we want to transform 4-dim vector into 2-dim vector, we can project the input with the matrix W above as follows.\n","\n","\n","$$ Y = X \\times W $$\n","\n","where Y is a 150x2 matrix (150 rows of records, each with 2 features)."]},{"cell_type":"code","metadata":{"id":"eKSSE_Yhe_Mv","colab_type":"code","colab":{}},"source":["Y = X_std_sc.dot(proj_matrix)\n","\n","with plt.style.context('bmh'):\n","    plt.figure(figsize=(8,5))\n","    for lab, col in zip(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'),\n","                        ('blue', 'red', 'green')):\n","        plt.scatter(Y[y==lab, 0],\n","                    Y[y==lab, 1],\n","                    label=lab,\n","                    c=col,)\n","    plt.xlabel('Component 1')\n","    plt.ylabel('Component 2')\n","    plt.legend(loc='lower center')\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"azB0OUfde_My","colab_type":"text"},"source":["## Shortcut in scikit-learn package"]},{"cell_type":"code","metadata":{"id":"jYg-ccdre_Mz","colab_type":"code","colab":{}},"source":["from sklearn.decomposition import PCA as sklearnPCA\n","pca_model = sklearnPCA(n_components=2)\n","Y_trans = pca_model.fit_transform(X_std_sc)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CbZvRtNke_M3","colab_type":"code","colab":{}},"source":["with plt.style.context('seaborn-whitegrid'):\n","    plt.figure(figsize=(8, 5))\n","    for lab, col in zip(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'),\n","                        ('blue', 'red', 'green')):\n","        plt.scatter(Y_trans[y==lab, 0],\n","                    Y_trans[y==lab, 1],\n","                    label=lab,\n","                    c=col,)\n","    plt.xlabel('Component 1')\n","    plt.ylabel('Component 2')\n","    plt.legend(loc='lower center')\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CsKuwmaSe_M8","colab_type":"text"},"source":["## See the differences?\n","\n","We did that manually. Notice the second axis, if we multiply -1 to the second component, we get the same thing."]},{"cell_type":"code","metadata":{"id":"bZyIpXh4e_M9","colab_type":"code","colab":{}},"source":["second_proj_matrix = np.hstack((eig_pairs[0][1].reshape(4,1),\n","                      -eig_pairs[1][1].reshape(4,1)))\n","\n","print('Projection Matrix :\\n', second_proj_matrix)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1Flu_ode_NF","colab_type":"code","colab":{}},"source":["Y = X_std_sc.dot(second_proj_matrix)\n","\n","with plt.style.context('seaborn-whitegrid'):\n","    plt.figure(figsize=(8,5))\n","    for lab, col in zip(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'),\n","                        ('blue', 'red', 'green')):\n","        plt.scatter(Y[y==lab, 0],\n","                    Y[y==lab, 1],\n","                    label=lab,\n","                    c=col,)\n","    plt.xlabel('Component 1')\n","    plt.ylabel('Component 2')\n","    plt.legend(loc='lower center')\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oBVUDfQbe_NR","colab_type":"text"},"source":["### Try to do PCA by yourself on \"sample_data.csv\""]},{"cell_type":"code","metadata":{"id":"bpFNqHXlfums","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}